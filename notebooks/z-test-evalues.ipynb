{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc376a5",
   "metadata": {},
   "source": [
    "### Date updated\n",
    "2024-05-01\n",
    "\n",
    "### Authors\n",
    "Reshama S\n",
    "\n",
    "### Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4e6991-bede-48bb-bccf-a99321aa4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pprint\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0bd6c5-7ad2-4571-8286-fe8201ddf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = {}\n",
    "\n",
    "# print(\"original dictionary: \", dict_example)\n",
    "\n",
    "# dict_example['a'] = 100  # existing key, overwrite\n",
    "# dict_example['c'] = 3  # new key, add\n",
    "# dict_example['d'] = 4  # new key, add \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0180da8d-c06b-4ce1-a997-65d756790bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AJ_IMG_3334\n",
      "{'rouge1': 0.912751677852349, 'rouge2': 0.8224719101123596, 'rougeL': 0.9038031319910516, 'rougeLsum': 0.9038031319910516}\n",
      "Levenshtein disagreement: 156\n",
      "Levensshtein ratio: 0.9153952843273232\n",
      "--------------------------------------------------\n",
      "AJ_IMG_3335\n",
      "{'rouge1': 0.8080229226361031, 'rouge2': 0.7146974063400576, 'rougeL': 0.8080229226361031, 'rougeLsum': 0.8080229226361031}\n",
      "Levenshtein disagreement: 303\n",
      "Levensshtein ratio: 0.8016928657799275\n",
      "--------------------------------------------------\n",
      "AP_IMG_3383\n",
      "{'rouge1': 0.8942307692307694, 'rouge2': 0.8019323671497584, 'rougeL': 0.8749999999999999, 'rougeLsum': 0.8894230769230769}\n",
      "Levenshtein disagreement: 226\n",
      "Levensshtein ratio: 0.8469493278179938\n",
      "--------------------------------------------------\n",
      "AP_IMG_3384\n",
      "{'rouge1': 0.8087167070217919, 'rouge2': 0.6763990267639904, 'rougeL': 0.7796610169491525, 'rougeLsum': 0.8038740920096852}\n",
      "Levenshtein disagreement: 379\n",
      "Levensshtein ratio: 0.7931034482758621\n",
      "--------------------------------------------------\n",
      "BM_IMG_3480\n",
      "{'rouge1': 0.8449367088607596, 'rouge2': 0.6952380952380952, 'rougeL': 0.800632911392405, 'rougeLsum': 0.8259493670886077}\n",
      "Levenshtein disagreement: 435\n",
      "Levensshtein ratio: 0.8181818181818181\n",
      "--------------------------------------------------\n",
      "BM_IMG_3481\n",
      "{'rouge1': 0.7617328519855596, 'rouge2': 0.6014492753623187, 'rougeL': 0.707581227436823, 'rougeLsum': 0.7545126353790613}\n",
      "Levenshtein disagreement: 470\n",
      "Levensshtein ratio: 0.7626281807823775\n",
      "--------------------------------------------------\n",
      "MW_IMG_3200\n",
      "{'rouge1': 0.7508650519031141, 'rouge2': 0.5833333333333335, 'rougeL': 0.7024221453287197, 'rougeLsum': 0.7404844290657439}\n",
      "Levenshtein disagreement: 539\n",
      "Levensshtein ratio: 0.7675407512402551\n",
      "--------------------------------------------------\n",
      "MW_IMG_3201\n",
      "{'rouge1': 0.8780487804878048, 'rouge2': 0.7459016393442623, 'rougeL': 0.8536585365853658, 'rougeLsum': 0.8536585365853658}\n",
      "Levenshtein disagreement: 117\n",
      "Levensshtein ratio: 0.8741379310344828\n",
      "--------------------------------------------------\n",
      "PG_IMG_3189\n",
      "{'rouge1': 0.81875, 'rouge2': 0.6269592476489029, 'rougeL': 0.753125, 'rougeLsum': 0.7875}\n",
      "Levenshtein disagreement: 513\n",
      "Levensshtein ratio: 0.7948463825569871\n",
      "--------------------------------------------------\n",
      "PG_IMG_3190\n",
      "{'rouge1': 0.8611898016997167, 'rouge2': 0.7635327635327634, 'rougeL': 0.8498583569405099, 'rougeLsum': 0.8498583569405099}\n",
      "Levenshtein disagreement: 190\n",
      "Levensshtein ratio: 0.8547008547008547\n",
      "--------------------------------------------------\n",
      "RF_IMG_3240\n",
      "{'rouge1': 0.89419795221843, 'rouge2': 0.7697594501718212, 'rougeL': 0.8668941979522184, 'rougeLsum': 0.8873720136518771}\n",
      "Levenshtein disagreement: 178\n",
      "Levensshtein ratio: 0.8474341192787795\n",
      "--------------------------------------------------\n",
      "RF_IMG_3241\n",
      "{'rouge1': 0.9210526315789473, 'rouge2': 0.847682119205298, 'rougeL': 0.9210526315789473, 'rougeLsum': 0.9144736842105264}\n",
      "Levenshtein disagreement: 81\n",
      "Levensshtein ratio: 0.9309878213802436\n",
      "--------------------------------------------------\n",
      "SS_IMG_2862\n",
      "{'rouge1': 0.9158415841584159, 'rouge2': 0.791044776119403, 'rougeL': 0.8811881188118812, 'rougeLsum': 0.9009900990099011}\n",
      "Levenshtein disagreement: 182\n",
      "Levensshtein ratio: 0.9004329004329005\n",
      "--------------------------------------------------\n",
      "SS_IMG_2863\n",
      "{'rouge1': 0.7400881057268723, 'rouge2': 0.5866666666666667, 'rougeL': 0.7312775330396477, 'rougeLsum': 0.7312775330396477}\n",
      "Levenshtein disagreement: 208\n",
      "Levensshtein ratio: 0.7803521779425394\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dir_human = \"../data/transcripts-clinician/\"\n",
    "dir_ai = \"../data/transcripts-whisper/\"\n",
    "\n",
    "\n",
    "def evaltext(filename):\n",
    "    print(filename)\n",
    "    file = open(dir_human + filename + \".txt\", \"r\")\n",
    "    content_human = file.read()\n",
    "    file.close()\n",
    "    #print(content_human)\n",
    "    #print(\"-\" * 50)\n",
    "    \n",
    "    file_ai = open(dir_ai + filename + \".txt\", \"r\")\n",
    "    content_ai = file_ai.read()\n",
    "    file_ai.close()\n",
    "    #print(content_ai)\n",
    "    #print(\"-\" * 50)\n",
    "\n",
    "    # load the metric (from Hugging Face)\n",
    "    score = evaluate.load('rouge')\n",
    "\n",
    "    results = score.compute(predictions=[content_ai],\n",
    "                         references=[content_human])\n",
    "    print(results)\n",
    "    dict_scores[filename] = results\n",
    "\n",
    "    disagreement = distance(content_human, content_ai)\n",
    "    print(f\"Levenshtein disagreement: {disagreement}\")\n",
    "    \n",
    "    ratiov = ratio(content_human, content_ai)\n",
    "    print(f\"Levensshtein ratio: {ratiov}\")\n",
    "    print('-' * 50)\n",
    "    \n",
    "evaltext(\"AJ_IMG_3334\")\n",
    "evaltext(\"AJ_IMG_3335\")\n",
    "evaltext(\"AP_IMG_3383\")\n",
    "evaltext(\"AP_IMG_3384\")\n",
    "evaltext(\"BM_IMG_3480\")\n",
    "evaltext(\"BM_IMG_3481\")\n",
    "evaltext(\"MW_IMG_3200\")\n",
    "evaltext(\"MW_IMG_3201\")\n",
    "evaltext(\"PG_IMG_3189\")\n",
    "evaltext(\"PG_IMG_3190\")\n",
    "evaltext(\"RF_IMG_3240\")\n",
    "evaltext(\"RF_IMG_3241\")\n",
    "evaltext(\"SS_IMG_2862\")\n",
    "evaltext(\"SS_IMG_2863\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637ad70-fa59-4b01-b43b-6cf7cbdc2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03a541e-f9aa-4170-83f0-a85e4f103a5b",
   "metadata": {},
   "source": [
    "### ROUGE score\n",
    "- A ROUGE score close to zero indicates poor similarity between candidate and references. \n",
    "- A ROUGE score close to one indicates strong similarity between candidate and references. \n",
    "- If candidate is identical to one of the reference documents, then score is 1.\n",
    "\n",
    "### Levenshtein score\n",
    "https://rapidfuzz.github.io/Levenshtein/levenshtein.html#distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5383e1-16b5-437c-bb67-47dd8e2c2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c5711-83ca-4ac7-a532-078dd32dc2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c74dec-5f5c-4267-a83f-f7dbc99d7501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e592836-1dae-43cc-9731-b49f0b8620cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e4216-b341-4bd7-a8d7-3f95fd90083a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8744ba8-2767-4bfd-a78a-803d6da5ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc09ef2-ddc7-41f6-84ed-b89bce768b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb39e43-31e4-4aaa-aa2e-ede4eefb9905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2149368-eca6-499c-8a9b-47a6775b56ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc4847-df81-4d3e-be31-09f006751ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81631c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bdb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480e346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2362e9a-26c5-42af-8c90-213d3295c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# load the metric (from Hugging Face)\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ad0fee-24da-4fcd-b9b8-2497cb9e18c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.6666666666666665, 'rouge2': 0.5714285714285715, 'rougeL': 0.6666666666666665, 'rougeLsum': 0.6666666666666665}\n"
     ]
    }
   ],
   "source": [
    "predictions = [\"My name is Mrs Reshama\"]\n",
    "references = [\"My name is Rachel\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6921eff-3b50-46ec-ad7f-402bf52d7fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75699058",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1_sladjana = (\"\"\"Well, we went to Italy. I enjoyed Italy, enjoyed the food. \\\n",
    "I enjoyed the wine and the women are fantastic. Um its not the safest place in the world but you kind of live with, \\\n",
    "you kind you live with. You know you're supposed to lock your house and close your windows and all that staff. \\\n",
    "Okay. And but everything was fine I mean. No, I lived there. Stayed there for about three years. Naples. \\\n",
    "Lovely place. But like I said its not, its not the safest place to live. \\\n",
    "I spoke a little bit, yeah, a little bit. Yes I did. I worked at the gym. \\\n",
    "She yeah she was uh, uh she ran a tourist place, you know where people want to take a trip. \\\n",
    "She had a lot of people to work for her but people want to take a trip or whatever and she set it up.\"\"\")\n",
    "    \n",
    "print(output1_sladjana)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1eeef-d74f-43c3-b4a3-1687515e7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2_whisper = (\"\"\"While we went to Italy, I enjoyed Italy, enjoyed the food. \\\n",
    "I enjoyed the wine and the women are fantastic. It's not the safest place in the world, \\\n",
    "but you kind of live with it. You live with it. You know, you're supposed to lock your \\\n",
    "house and close your windows and all that stuff. Okay. But everything was fine. No, I lived there. \\\n",
    "Stayed there for about three years. Naples. Lovely place But like I said, it's not the safest place to live. \\\n",
    "I spoke a little bit. Yes, I did. I worked at the adagem. She ran a tourist place. People want to take a trip. \\\n",
    "She had a lot of people who worked for her. She wanted to take a trip or whatever. She said it out. I'll need it.\"\"\")\n",
    "\n",
    "print(output2_whisper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7dfeef-2dda-41ca-aba1-8dc6eaed82ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a0267-353a-4e39-af0f-100d94c58a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output3_assemblyai = (\"\"\"Well, we went to Italy. I enjoyed Italy. Enjoyed the food. \n",
    "I enjoyed the wine. And the women are fantastic. \n",
    "It's not the safest place in the world. You kind of live with. You kind of. You live with it. \n",
    "You know, you're supposed to lock your house and close your windows and all that stuff, but everything was fine.\n",
    "No, I lived there.\n",
    "Stayed there for about three years. What part? Naples. \n",
    "Naples. Lovely place\n",
    "but like I said, it's not the safest place to live. But did.\n",
    "I spoke a little bit, yeah, a little bit.\n",
    "Yes, I did. I worked at a gym.\n",
    "Her job, right? Yeah, she was a. She ran a tourist place where people want to take a a trip. \n",
    "She had a lot of people work for her, but people want to take a trip or whatever but people want to take a trip or whatever. Then she'd set it.\n",
    "\"\"\")\n",
    "\n",
    "print(output3_assemblyai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ca827-8f06-45d3-b4e0-f4cb65a1c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "# load the metric (from Hugging Face)\n",
    "score = evaluate.load('rouge')\n",
    "score = evaluate.load(\"accuracy\")\n",
    "\n",
    "predictions = output2_whisper\n",
    "references = output1_sladjana\n",
    "results = score.compute(predictions=[predictions],\n",
    "                         references=[references])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62347867-095f-4324-b947-762ae1d12b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output3_assemblyai\n",
    "references = output1_sladjana\n",
    "results = rouge.compute(predictions=[predictions],\n",
    "                         references=[references])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c12350-6989-424a-a9cf-2a95f46f7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output3_assemblyai\n",
    "references = output2_whisper\n",
    "results = rouge.compute(predictions=[predictions],\n",
    "                         references=[references])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68965c-c628-4da0-8966-2246c030dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example\n",
    "from nltk import agreement\n",
    "rater1 = [1,1,1]\n",
    "rater2 = [1,1,0]\n",
    "rater3 = [0,1,1]\n",
    "\n",
    "taskdata=[[0,str(i),str(rater1[i])] for i in range(0,len(rater1))]+[[1,str(i),str(rater2[i])] for i in range(0,len(rater2))]+[[2,str(i),str(rater3[i])] for i in range(0,len(rater3))]\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "print(\"alpha \" +str(ratingtask.alpha()))\n",
    "print(\"scotts \" + str(ratingtask.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23cbba-2569-4878-b913-6f74df8481b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rater1 = [output1_sladjana]\n",
    "rater2 = [output2_whisper]\n",
    "rater3 = [output3_assemblyai]\n",
    "\n",
    "taskdata=[[0,str(i),str(rater1[i])] for i in range(0,len(rater1))]+[[1,str(i),str(rater2[i])] for i in range(0,len(rater2))]+[[2,str(i),str(rater3[i])] for i in range(0,len(rater3))]\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "print(\"alpha \" +str(ratingtask.alpha()))\n",
    "print(\"scotts \" + str(ratingtask.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932551b-71fb-4413-aab5-fa76e7379998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4708721-53c4-484f-9d60-d551ef8abbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "first_sentence = \"I see three people who look like they are having a picnic.\"\n",
    "second_sentence = \"I see a dozen people who look like they are walking to the movies.\"\n",
    "\n",
    "levenshtein_distance = distance(first_sentence, second_sentence)\n",
    "\n",
    "print(f\"Levenshtein distance: {levenshtein_distance}\")\n",
    "\n",
    "# Calculate normalized distance (between 0 and 1)\n",
    "sentence_length = max(len(first_sentence), len(second_sentence))\n",
    "normalized_distance = levenshtein_distance / sentence_length\n",
    "\n",
    "print(f\"Normalized Levenshtein distance: {normalized_distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d54842-6d21-4a4c-b2ec-ef92a4183bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_distance = distance(output1_sladjana, output2_whisper)\n",
    "\n",
    "print(f\"Levenshtein distance: {levenshtein_distance}\")\n",
    "\n",
    "# Calculate normalized distance (between 0 and 1)\n",
    "sentence_length = max(len(first_sentence), len(second_sentence))\n",
    "normalized_distance = levenshtein_distance / sentence_length\n",
    "\n",
    "print(f\"Normalized Levenshtein distance: {normalized_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29427dad-3e9f-4094-8f45-0b51a1295a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800628db-440a-4d08-92c3-e8784183ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8612ea-6018-4a89-9631-d2031d8446ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [['this', 'is', 'a', 'test'], ['this', 'is', 'another', 'test']]  # Multiple references\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "\n",
    "score = sentence_bleu(references, candidate)\n",
    "print(score)  # Output: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491f6d6-442b-45d2-94e1-bbe1156ca6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "#references = [['this', 'is', 'a', 'good', 'translation'], ['another', 'good', 'translation', 'example']]\n",
    "references = [['this', 'is', 'a', 'good', 'translation']]\n",
    "\n",
    "candidate = ['this', 'is', 'a', 'good', 'example']\n",
    "\n",
    "# Emphasize unigrams and bigrams, while slightly considering trigrams:\n",
    "weights = (0.5, 0.4, 0.2, 0)  # Weights for 1-gram, 2-gram, 3-gram, 4-gram\n",
    "#weights = (0.1, 0.1, 0.1, 0)\n",
    "weights = (0.1, 0.2, 0.05, 0)\n",
    "weights = (0.5, 0, 0, 0)\n",
    "weights = (1.0, 0, 0, 0) # this gives 80% score, when only checking words\n",
    "weights = (0.6, 0.3, 0.1, 0)\n",
    "\n",
    "score = sentence_bleu(references, candidate, weights=weights)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49dc8c-5128-434e-9312-5c840a439314",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output1_sladjana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c80b53-cfff-44a1-8886-9852744f6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1_slad_tokens = nltk.word_tokenize(output1_sladjana)\n",
    "print(out1_slad_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba046e-2f9c-4c1f-85e6-ee08a7a9649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2_whis_tokens = nltk.word_tokenize(output2_whisper)\n",
    "print(out2_whis_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abd324-47c2-468f-9d1a-202141dae98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1.0, 0, 0, 0) # this gives 80% score, when only checking words\n",
    "weights = (0.5, 0.4, 0.1, 0)\n",
    "\n",
    "score = sentence_bleu(out1_slad_tokens, out2_whis_tokens, weights=weights)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4650bac-f56e-432c-bb70-88f69474d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "sentence1 = \"I see three people who look like they are having a picnic.\"\n",
    "sentence2 = \"I see a dozen people who seem to be walking to the movies.\"\n",
    "\n",
    "disagreement = distance(sentence1, sentence2)\n",
    "\n",
    "print(f\"Levenshtein disagreement: {disagreement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1b54e-d403-4e45-bb18-fdb93863619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import jaccard_similarity\n",
    "\n",
    "sentence1_tokens = nltk.word_tokenize(sentence1)\n",
    "sentence2_tokens = nltk.word_tokenize(sentence2)\n",
    "\n",
    "disagreement_percent = (1 - jaccard_similarity(sentence1_tokens, sentence2_tokens)) * 100\n",
    "\n",
    "print(f\"Percent rater disagreement (Jaccard): {disagreement_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ddf07-0b93-457d-8aa7-e83ea1794889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall nltk\n",
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425edfa-85d1-48c0-a575-ed81389a86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work: \"inconsistent length\"\n",
    "#import nltk\n",
    "#from nltk.metrics import jaccard_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "sentence1_tokens = nltk.word_tokenize(content_human)\n",
    "    sentence2_tokens = nltk.word_tokenize(content_ai)\n",
    "    disagreement_percent = (1 - jaccard_score(sentence1_tokens, sentence2_tokens)) * 100\n",
    "    print(f\"Percent rater disagreement (Jaccard): {disagreement_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f084ec-07e2-4124-b9f0-af8c485981e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def tokenize(s):\n",
    "    return re.split('\\s+', s)\n",
    "\n",
    "def evalbleu(filename):\n",
    "    print(filename)\n",
    "    file = open(dir_human + filename + \".txt\", \"r\")\n",
    "    content_human = file.read()\n",
    "    file.close()\n",
    "    #print(content_human)\n",
    "    #print(\"-\" * 50)\n",
    "    \n",
    "    file_ai = open(dir_ai + filename + \".txt\", \"r\")\n",
    "    content_ai = file_ai.read()\n",
    "    file_ai.close()\n",
    "    #print(content_ai)\n",
    "    #print(\"-\" * 50)\n",
    "\n",
    "    print('-' * 50)\n",
    "    l1 = tokenize(content_human)\n",
    "    l2 = tokenize(content_ai)\n",
    "\n",
    "    # Emphasize unigrams and bigrams, while slightly considering trigrams:\n",
    "    weights = (0.5, 0.4, 0.2, 0)  # Weights for 1-gram, 2-gram, 3-gram, 4-gram\n",
    "    #weights = (0.1, 0.1, 0.1, 0)\n",
    "    weights = (0.1, 0.2, 0.05, 0)\n",
    "    weights = (0.5, 0, 0, 0)\n",
    "    weights = (1.0, 0, 0, 0) # this gives 80% score, when only checking words\n",
    "    weights = (0.6, 0.3, 0.1, 0)\n",
    "\n",
    "    score = sentence_bleu(l1, l2, weights=weights)\n",
    "    print(score)  # Output: 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9dfd5-dbde-4b28-b2a5-6d68ecf99397",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalbleu(\"RF_IMG_3241\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0217b-94e6-4fa5-9924-230126865c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686c44c-34ef-4425-a408-aeea056116e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f3a01-c497-4c28-93d8-04968fd1655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f5082-9067-4af0-bc99-b17c3b0a1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metric (from Hugging Face)\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31495466-acbe-4ee7-b6ba-18a781f61247",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"My name is Mrs Reshama\"]\n",
    "references = [\"My name is Rachel\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484f7d1-1d98-42d7-9ae9-fd1e78e664ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5210b-580c-4142-baf7-1f8377c09c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b0b26-1e82-4c23-a8cf-16b848b720b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
