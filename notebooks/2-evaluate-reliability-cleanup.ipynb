{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc376a5",
   "metadata": {},
   "source": [
    "### Info\n",
    "- Date: 2024-06-12\n",
    "- Author: Reshama S\n",
    "- Location: https://github.com/NoLaB-Lab/nlp-project1\n",
    "\n",
    "### Description\n",
    "- Evalute human vs ai transcripts\n",
    "\n",
    "### ROUGE score\n",
    "- A ROUGE score close to zero indicates poor similarity between candidate and references. \n",
    "- A ROUGE score close to one indicates strong similarity between candidate and references. \n",
    "- If candidate is identical to one of the reference documents, then score is 1.\n",
    "\n",
    "### Levenshtein score\n",
    "https://rapidfuzz.github.io/Levenshtein/levenshtein.html#distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4e6991-bede-48bb-bccf-a99321aa4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pprint\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0bd6c5-7ad2-4571-8286-fe8201ddf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_human = \"../data/transcripts-clinician/\"\n",
    "dir_ai = \"../data/transcripts-whisper/\"\n",
    "\n",
    "dict_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c74dec-5f5c-4267-a83f-f7dbc99d7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://towardsdatascience.com/side-by-side-comparison-of-strings-in-python-b9491ac858\n",
    "\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "def tokenize(s):\n",
    "    return re.split('\\s+', s)\n",
    "def untokenize(ts):\n",
    "    return ' '.join(ts)\n",
    "        \n",
    "def equalize(s1, s2):\n",
    "    l1 = tokenize(s1)\n",
    "    l2 = tokenize(s2)\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    prev = difflib.Match(0,0,0)\n",
    "    for match in difflib.SequenceMatcher(a=l1, b=l2).get_matching_blocks():\n",
    "        if (prev.a + prev.size != match.a):\n",
    "            for i in range(prev.a + prev.size, match.a):\n",
    "                res2 += ['_' * len(l1[i])]\n",
    "            res1 += l1[prev.a + prev.size:match.a]\n",
    "        if (prev.b + prev.size != match.b):\n",
    "            for i in range(prev.b + prev.size, match.b):\n",
    "                res1 += ['_' * len(l2[i])]\n",
    "            res2 += l2[prev.b + prev.size:match.b]\n",
    "        res1 += l1[match.a:match.a+match.size]\n",
    "        res2 += l2[match.b:match.b+match.size]\n",
    "        prev = match\n",
    "    return untokenize(res1), untokenize(res2)\n",
    "\n",
    "def insert_newlines(string, every=64, window=10):\n",
    "    result = []\n",
    "    from_string = string\n",
    "    while len(from_string) > 0:\n",
    "        cut_off = every\n",
    "        if len(from_string) > every:\n",
    "            while (from_string[cut_off-1] != ' ') and (cut_off > (every-window)):\n",
    "                cut_off -= 1\n",
    "        else:\n",
    "            cut_off = len(from_string)\n",
    "        part = from_string[:cut_off]\n",
    "        result += [part]\n",
    "        from_string = from_string[cut_off:]\n",
    "    return result\n",
    "\n",
    "def show_comparison(s1, s2, width=40, margin=10, sidebyside=True, compact=False):\n",
    "    s1, s2 = equalize(s1,s2)\n",
    "\n",
    "    if sidebyside:\n",
    "        s1 = insert_newlines(s1, width, margin)\n",
    "        s2 = insert_newlines(s2, width, margin)\n",
    "        if compact:\n",
    "            for i in range(0, len(s1)):\n",
    "                lft = re.sub(' +', ' ', s1[i].replace('_', '')).ljust(width)\n",
    "                rgt = re.sub(' +', ' ', s2[i].replace('_', '')).ljust(width) \n",
    "                print(lft + ' | ' + rgt + ' | ')        \n",
    "        else:\n",
    "            for i in range(0, len(s1)):\n",
    "                lft = s1[i].ljust(width)\n",
    "                rgt = s2[i].ljust(width)\n",
    "                print(lft + ' | ' + rgt + ' | ')\n",
    "    else:\n",
    "        print(s1)\n",
    "        print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969abd45-a610-4a31-af7f-c55294e08a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtext(filename):\n",
    "    #print(filename)\n",
    "    file = open(dir_human + filename + \".txt\", \"r\")\n",
    "    content_human = file.read()\n",
    "    file.close()\n",
    "    #print(content_human)\n",
    "    #print(\"-\" * 50)\n",
    "    \n",
    "    file_ai = open(dir_ai + filename + \".txt\", \"r\")\n",
    "    content_ai = file_ai.read()\n",
    "    file_ai.close()\n",
    "    #print(content_ai)\n",
    "    #print(\"-\" * 50)\n",
    "    return filename, content_human, content_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49e549-68c6-4bc0-bfbc-971c83ba171d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0180da8d-c06b-4ce1-a997-65d756790bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaltext(filename, content_human, content_ai):\n",
    "    #print(filename)\n",
    "    # load the metric (from Hugging Face)\n",
    "    score = evaluate.load('rouge')\n",
    "    #score = evaluate.load(\"accuracy\") # this gives error\n",
    "\n",
    "    results = score.compute(predictions=[content_ai],\n",
    "                         references=[content_human])\n",
    "    print(results)\n",
    "    dict_scores[filename] = results\n",
    "\n",
    "    disagreement = distance(content_human, content_ai)\n",
    "    print(f\"Levenshtein disagreement: {disagreement}\")\n",
    "    \n",
    "    ratiov = ratio(content_human, content_ai)\n",
    "    print(f\"Levensshtein ratio: {ratiov}\")\n",
    "\n",
    "    # Calculate normalized distance (between 0 and 1)\n",
    "    levenshtein_distance = distance(content_human, content_ai)\n",
    "    print(f\"Levenshtein distance: {levenshtein_distance}\")\n",
    "    sentence_length = max(len(content_human), len(content_ai))\n",
    "    normalized_distance = levenshtein_distance / sentence_length\n",
    "\n",
    "    print(f\"Normalized Levenshtein distance: {normalized_distance}\")\n",
    "\n",
    "    print('-' * 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55bdf90-9a61-4bc7-9bbc-edb666ae24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comptext(filename, content_human, content_ai):\n",
    "    show_comparison(content_human, content_ai, width=50, sidebyside=True, compact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c678355-a80a-4d58-81e5-15738d71c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runanalysis(patientnum, printcomp):\n",
    "    print(patientnum)\n",
    "    filename, content_human, content_ai = readtext(patientnum)\n",
    "    evaltext(filename, content_human, content_ai)\n",
    "    if printcomp == 1:\n",
    "        comptext(filename, content_human, content_ai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd53018e-1594-47e5-a646-8c9fcdf73f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AJ_IMG_3334\n",
      "{'rouge1': 0.945054945054945, 'rouge2': 0.8741721854304636, 'rougeL': 0.9362637362637363, 'rougeLsum': 0.9362637362637363}\n",
      "Levenshtein disagreement: 119\n",
      "Levensshtein ratio: 0.9315693430656934\n",
      "Levenshtein distance: 119\n",
      "Normalized Levenshtein distance: 0.10798548094373865\n",
      "----------------------------------------------------\n",
      "AJ_IMG_3335\n",
      "{'rouge1': 0.8763440860215055, 'rouge2': 0.7891891891891892, 'rougeL': 0.8709677419354839, 'rougeLsum': 0.8709677419354839}\n",
      "Levenshtein disagreement: 175\n",
      "Levensshtein ratio: 0.8883903533370724\n",
      "Levenshtein distance: 175\n",
      "Normalized Levenshtein distance: 0.18248175182481752\n",
      "----------------------------------------------------\n",
      "AP_IMG_3383\n",
      "{'rouge1': 0.9320388349514563, 'rouge2': 0.848780487804878, 'rougeL': 0.9126213592233011, 'rougeLsum': 0.9126213592233011}\n",
      "Levenshtein disagreement: 146\n",
      "Levensshtein ratio: 0.8980021030494216\n",
      "Levenshtein distance: 146\n",
      "Normalized Levenshtein distance: 0.15320041972717732\n",
      "----------------------------------------------------\n",
      "AP_IMG_3384\n",
      "{'rouge1': 0.8598574821852732, 'rouge2': 0.7350835322195703, 'rougeL': 0.8313539192399051, 'rougeLsum': 0.8266033254156769}\n",
      "Levenshtein disagreement: 312\n",
      "Levensshtein ratio: 0.8434053815615351\n",
      "Levenshtein distance: 312\n",
      "Normalized Levenshtein distance: 0.2578512396694215\n",
      "----------------------------------------------------\n",
      "BM_IMG_3480\n",
      "{'rouge1': 0.8822605965463108, 'rouge2': 0.7622047244094489, 'rougeL': 0.8414442700156985, 'rougeLsum': 0.8414442700156985}\n",
      "Levenshtein disagreement: 381\n",
      "Levensshtein ratio: 0.8475043029259897\n",
      "Levenshtein distance: 381\n",
      "Normalized Levenshtein distance: 0.26149622512010984\n",
      "----------------------------------------------------\n",
      "BM_IMG_3481\n",
      "{'rouge1': 0.8099467140319715, 'rouge2': 0.7023172905525846, 'rougeL': 0.7673179396092362, 'rougeLsum': 0.7992895204262876}\n",
      "Levenshtein disagreement: 384\n",
      "Levensshtein ratio: 0.806047197640118\n",
      "Levenshtein distance: 384\n",
      "Normalized Levenshtein distance: 0.28029197080291973\n",
      "----------------------------------------------------\n",
      "MW_IMG_3200\n",
      "{'rouge1': 0.7904599659284497, 'rouge2': 0.6564102564102564, 'rougeL': 0.7461669505962522, 'rougeLsum': 0.7666098807495741}\n",
      "Levenshtein disagreement: 492\n",
      "Levensshtein ratio: 0.7916813535424745\n",
      "Levenshtein distance: 492\n",
      "Normalized Levenshtein distance: 0.3374485596707819\n",
      "----------------------------------------------------\n",
      "MW_IMG_3201\n",
      "{'rouge1': 0.9477911646586347, 'rouge2': 0.8744939271255061, 'rougeL': 0.9397590361445782, 'rougeLsum': 0.9397590361445782}\n",
      "Levenshtein disagreement: 73\n",
      "Levensshtein ratio: 0.9218884120171674\n",
      "Levenshtein distance: 73\n",
      "Normalized Levenshtein distance: 0.12436115843270869\n",
      "----------------------------------------------------\n",
      "PG_IMG_3189\n",
      "{'rouge1': 0.8430769230769231, 'rouge2': 0.6697530864197531, 'rougeL': 0.7753846153846154, 'rougeLsum': 0.8061538461538462}\n",
      "Levenshtein disagreement: 452\n",
      "Levensshtein ratio: 0.8183006535947712\n",
      "Levenshtein distance: 452\n",
      "Normalized Levenshtein distance: 0.27443837279902855\n",
      "----------------------------------------------------\n",
      "PG_IMG_3190\n",
      "{'rouge1': 0.888268156424581, 'rouge2': 0.8033707865168538, 'rougeL': 0.8770949720670392, 'rougeLsum': 0.8770949720670392}\n",
      "Levenshtein disagreement: 153\n",
      "Levensshtein ratio: 0.8771084337349397\n",
      "Levenshtein distance: 153\n",
      "Normalized Levenshtein distance: 0.17852975495915985\n",
      "----------------------------------------------------\n",
      "SS_IMG_2862\n",
      "{'rouge1': 0.9152542372881356, 'rouge2': 0.827250608272506, 'rougeL': 0.891041162227603, 'rougeLsum': 0.891041162227603}\n",
      "Levenshtein disagreement: 165\n",
      "Levensshtein ratio: 0.9072067828544512\n",
      "Levenshtein distance: 165\n",
      "Normalized Levenshtein distance: 0.15492957746478872\n",
      "----------------------------------------------------\n",
      "SS_IMG_2863\n",
      "{'rouge1': 0.8760330578512397, 'rouge2': 0.7666666666666666, 'rougeL': 0.8677685950413223, 'rougeLsum': 0.8677685950413223}\n",
      "Levenshtein disagreement: 112\n",
      "Levensshtein ratio: 0.8808290155440415\n",
      "Levenshtein distance: 112\n",
      "Normalized Levenshtein distance: 0.1821138211382114\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "runanalysis(\"AJ_IMG_3334\", printcomp=0)\n",
    "runanalysis(\"AJ_IMG_3335\", printcomp=0)\n",
    "\n",
    "runanalysis(\"AP_IMG_3383\", printcomp=0)\n",
    "runanalysis(\"AP_IMG_3384\", printcomp=0)\n",
    "\n",
    "runanalysis(\"BM_IMG_3480\", printcomp=0)\n",
    "runanalysis(\"BM_IMG_3481\", printcomp=0)\n",
    "\n",
    "# don't see these recordings in data-media directory, but clinician transcripts are available\n",
    "#runanalysis(\"HC1_RF_IMG_3240\", printcomp=0)\n",
    "#runanalysis(\"HC1_RF_IMG_3241\", printcomp=0)\n",
    "\n",
    "# typo in file name (fixed in code repo)\n",
    "# this file has a sort of UTC8 error: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 116: invalid continuation byte\n",
    "# update filename, remove . to _\n",
    "#runanalysis(\"HC2_SD_5_7_24_BestTrip\", printcomp=0)\n",
    "#runanalysis(\"HC2_SD_5_7_24_FirstJob\", printcomp=0)\n",
    "\n",
    "runanalysis(\"MW_IMG_3200\", printcomp=0)\n",
    "runanalysis(\"MW_IMG_3201\", printcomp=0)\n",
    "\n",
    "# recording: YES; clinician transcript: NO\n",
    "#runanalysis(\"PB_2.27.24_BestTrip\", printcomp=0)\n",
    "\n",
    "runanalysis(\"PG_IMG_3189\", printcomp=0)\n",
    "runanalysis(\"PG_IMG_3190\", printcomp=0)\n",
    "\n",
    "# recording: YES; clinician transcript: NO\n",
    "#runanalysis(\"RF_IMG_3240\", printcomp=0)\n",
    "#runanalysis(\"RF_IMG_3241\", printcomp=0)\n",
    "\n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 97: invalid continuation byte\n",
    "#runanalysis(\"SF_2.6.24_BestTrip\", printcomp=0)\n",
    "\n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 82: invalid continuation byte\n",
    "#runanalysis(\"SF_2.6.24_Childhood_memory\", printcomp=0)\n",
    "\n",
    "# clinician transcript name changed from 04.02.2024 to 04.03.2024\n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 57: invalid continuation byte\n",
    "#runanalysis(\"SG_BestTrip_04.03.2024\", printcomp=0)\n",
    "\n",
    "#UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 3: invalid continuation byte\n",
    "#runanalysis(\"SG_FirstJob_04.03.2024\", printcomp=0)\n",
    "\n",
    "runanalysis(\"SS_IMG_2862\", printcomp=0)\n",
    "runanalysis(\"SS_IMG_2863\", printcomp=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc0577c-1ab5-4ce9-9f36-83b6352649bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runanalysis(\"AJ_IMG_3334\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f98e99a-fead-4e42-a645-eff6f02bec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest score\n",
    "#runanalysis(\"RF_IMG_3241\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171b594f-51a2-4c0d-8da2-8ba91185183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest score\n",
    "#runanalysis(\"SS_IMG_2863\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d5e44-3a92-4289-a661-6e57659b640a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920a25db-7f5f-4c2a-8c66-5349e5b58dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: both texts are the same\n",
    "#runanalysis(\"test\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df002e3-2fb2-4f36-b1f8-df2fe7a1aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas\n",
    "#runanalysis(\"test1\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b155e3b8-95bf-4721-88eb-67ed2d04b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all periods\n",
    "#runanalysis(\"test2\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0071a841-ee3d-45e6-8e36-8bbfa91c7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texting types of words\n",
    "#runanalysis(\"test3\", printcomp=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619db17b-86f0-48de-81e0-0828d56cbf39",
   "metadata": {},
   "source": [
    "## Lowest patient score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46aa791c-1705-4a9f-9ee6-2fb697faec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest score\n",
    "#runanalysis(\"SS_IMG_2863-ptonly\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee730bb9-3301-4685-9a7a-84a44cb3c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest score\n",
    "# check clinical vs Assembly AI\n",
    "# Note: manually removed Clinician \n",
    "# Conclusion: Assembly AI has LOWER accuracy in transcription than Whisper\n",
    "# Assembly AI:  \n",
    "# Whisper AI:  \n",
    "\n",
    "#runanalysis(\"assemblyai-1speaker-2863\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6141523-5018-48e9-b750-0db65fa7058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest score\n",
    "#runanalysis(\"SS_IMG_2863\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31ced2f-31b2-4f3c-841b-c0e7ae3d56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient text only (exclude clinicians)\n",
    "#runanalysis(\"SS_IMG_2863-ptonly\", printcomp=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7422de57-dfeb-4e8a-986f-e9dadd6d13f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_IMG_2863-ptonly-clean\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/transcripts-clinician/SS_IMG_2863-ptonly-clean.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fix spelling: \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# remeber   ==> remember\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# wasnt     ==> wasn't\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# andall    ==> and all\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrunanalysis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSS_IMG_2863-ptonly-clean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintcomp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mrunanalysis\u001b[0;34m(patientnum, printcomp)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunanalysis\u001b[39m(patientnum, printcomp):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(patientnum)\n\u001b[0;32m----> 3\u001b[0m     filename, content_human, content_ai \u001b[38;5;241m=\u001b[39m \u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatientnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     evaltext(filename, content_human, content_ai)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m printcomp \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mreadtext\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadtext\u001b[39m(filename):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#print(filename)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdir_human\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     content_human \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m     file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp-project1/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/transcripts-clinician/SS_IMG_2863-ptonly-clean.txt'"
     ]
    }
   ],
   "source": [
    "# fix spelling: \n",
    "# remeber   ==> remember\n",
    "# wasnt     ==> wasn't\n",
    "# andall    ==> and all\n",
    "#runanalysis(\"SS_IMG_2863-ptonly-clean\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79248d-af33-4b07-a6bb-039777313c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix  \n",
    "#     ==>  \n",
    "#      ==>  \n",
    "#      ==>  \n",
    "#runanalysis(\"SS_IMG_2863-ptonly-clean2\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637ad70-fa59-4b01-b43b-6cf7cbdc2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5383e1-16b5-437c-bb67-47dd8e2c2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c5711-83ca-4ac7-a532-078dd32dc2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf979da-a5d3-4d51-bc68-3d4fd238a374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e8cd4-16e8-4dce-baca-94facd60031d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10020c94-724b-4d32-a2a1-430f8056a9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bdb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480e346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425edfa-85d1-48c0-a575-ed81389a86e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31495466-acbe-4ee7-b6ba-18a781f61247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
